{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2pT/2G5yROCvZTtRtUj7j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josejailson/tensorflow_data_api/blob/main/proto_buffer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IIXbWizvqB4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train, y_train = X_train_full[:5500], y_train_full[:5500]\n",
        "X_valid, y_valid = X_train_full[5500:], y_train_full[5500:]"
      ],
      "metadata": {
        "id": "PpeRXHcrqIKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
        "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))"
      ],
      "metadata": {
        "id": "mdFn0lXQqzye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.train import Int64List, BytesList\n",
        "from tensorflow.train import Feature, Features, Example\n",
        "\n",
        "\n",
        "def create_example(image, label):\n",
        "  image_data = tf.io.serialize_tensor(image)\n",
        "  return Example(\n",
        "      features=Features(\n",
        "          feature={\n",
        "              \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
        "              \"label\": Feature(int64_list=Int64List(value=[label]))\n",
        "          }\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "RcchB0HkrVvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import ExitStack\n",
        "\n",
        "def write_tfrecords(name, dataset, n_shards=10):\n",
        "  paths = [\"{}.tfrecords-{:05d}-{:05d}\".format(name, index, n_shards)\n",
        "            for index in range(n_shards)]\n",
        "  with ExitStack() as stack:\n",
        "    writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
        "                for path in paths]\n",
        "    for index, (image, label) in dataset.enumerate():\n",
        "      shard = index % n_shards\n",
        "      example = create_example(image, label)\n",
        "      writers[shard].write(example.SerializeToString())\n",
        "  return paths"
      ],
      "metadata": {
        "id": "kghZ2lmVsRK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
        "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)\n",
        "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)"
      ],
      "metadata": {
        "id": "IpPZ-PpPtns_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_filepaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMMR4kSNuVoQ",
        "outputId": "05f483b6-b7c3-4b79-d5bd-83c11b69d928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my_fashion_mnist.train.tfrecords-00000-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00001-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00002-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00003-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00004-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00005-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00006-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00007-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00008-00010',\n",
              " 'my_fashion_mnist.train.tfrecords-00009-00010']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(tfrecord):\n",
        "  feature_descriptions = {\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
        "      \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
        "  }\n",
        "  example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
        "  image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
        "  image = tf.reshape(image, shape=[28,28])\n",
        "  return image, example[\"label\"]"
      ],
      "metadata": {
        "id": "V7Jg9ob8u6vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None, n_parse_threads=5, batch_size=32, cache=True):\n",
        "  dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
        "  if cache:\n",
        "    dataset = dataset.cache()\n",
        "    if shuffle_buffer_size:\n",
        "      dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "1CwEX3_KwYR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
        "valid_set = mnist_dataset(valid_filepaths)\n",
        "test_set = mnist_dataset(test_filepaths)"
      ],
      "metadata": {
        "id": "FT2yONQTxk7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_set.take(1):\n",
        "  for i in range(5):\n",
        "    plt"
      ],
      "metadata": {
        "id": "DWF15alZx_So"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}